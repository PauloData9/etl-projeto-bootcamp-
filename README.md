ğŸ“Œ **Pipeline ETL com IA Generativa â€” App de HÃ¡bitos**



ğŸ“– **VisÃ£o Geral**



Este projeto implementa um **pipeline ETL** **(Extract, Transform, Load)** completo, simulando o funcionamento de um **aplicativo de hÃ¡bitos pessoais**.

A soluÃ§Ã£o integra dados provenientes de uma **API REST**, realiza **enriquecimento com InteligÃªncia Artificial generativa** e carrega os dados transformados de volta na API.



O objetivo Ã© demonstrar, de forma prÃ¡tica, como pipelines de dados podem ser estruturados em cenÃ¡rios reais, combinando **engenharia de dados**, **consumo de APIs** e **IA aplicada**.





ğŸ¯ **Contexto do Problema**



Aplicativos de hÃ¡bitos dependem de dados comportamentais para fornecer recomendaÃ§Ãµes personalizadas aos usuÃ¡rios.

Neste projeto, cada usuÃ¡rio possui informaÃ§Ãµes como:



* hÃ¡bito principal



* frequÃªncia semanal



* objetivo pessoal



A partir desses dados, um modelo de linguagem Ã© utilizado para gerar **insights personalizados**, simulando recomendaÃ§Ãµes inteligentes dentro do aplicativo.





ğŸ—ï¸ **Arquitetura do Pipeline ETL**



ğŸ”¹ **Etapa 1 â€” Extract (CSV)**



* Leitura de um arquivo CSV contendo os IDs dos usuÃ¡rios



* ConversÃ£o dos IDs para uma lista Python



* ValidaÃ§Ã£o inicial dos dados de entrada





ğŸ”¹ **Etapa 2 â€” Extract (API)**



* Consulta dos dados completos de cada usuÃ¡rio via API REST



* RequisiÃ§Ãµes HTTP GET utilizando os IDs do CSV



* Filtragem automÃ¡tica de usuÃ¡rios invÃ¡lidos





ğŸ”¹ **Etapa 3 â€” Transform**



* Enriquecimento dos dados com IA generativa



* GeraÃ§Ã£o de insights personalizados com base:



	* no hÃ¡bito principal



	* na frequÃªncia semanal



* InserÃ§Ã£o estruturada dos insights no objeto do usuÃ¡rio





ğŸ”¹ **Etapa 4 â€” Load**



* PersistÃªncia dos dados enriquecidos na API



* AtualizaÃ§Ã£o individual de cada usuÃ¡rio via requisiÃ§Ã£o HTTP PUT



* ValidaÃ§Ã£o do sucesso da operaÃ§Ã£o por cÃ³digo de status HTTP





ğŸ”„ **Fluxo do Pipeline**



CSV (IDs)

  â†“

API (GET usuÃ¡rios)

  â†“

IA Generativa (insights personalizados)

  â†“

API (PUT usuÃ¡rios enriquecidos)





ğŸ› ï¸ **Tecnologias Utilizadas**



* **Python**



* **Pandas** â€” leitura e manipulaÃ§Ã£o de CSV



* **Requests** â€” consumo de API REST



* **OpenAI API** â€” geraÃ§Ã£o de insights com IA



* **JSON** â€” estrutura de dados



* **MockAPI** â€” simulaÃ§Ã£o de backend





ğŸ§  **DecisÃµes TÃ©cnicas**



* A separaÃ§Ã£o clara das etapas do ETL melhora a legibilidade e a manutenÃ§Ã£o do cÃ³digo.



* O uso de funÃ§Ãµes pequenas e reutilizÃ¡veis facilita testes e evoluÃ§Ã£o futura do pipeline.



* A transformaÃ§Ã£o com IA foi mantida independente da etapa de Load, seguindo boas prÃ¡ticas de engenharia de dados.



* O domÃ­nio do problema foi adaptado para um contexto nÃ£o bancÃ¡rio, garantindo originalidade em relaÃ§Ã£o a exemplos acadÃªmicos.





ğŸ“Œ **Exemplo de Dado Enriquecido**



{

 "id": "1",

 "name": "Paulo",

 "primary\_habit": "ExercÃ­cio fÃ­sico",

 "frequency\_per\_week": 3,

 "goal": "Criar consistÃªncia",

 "insights": \[

   {

     "habit": "ExercÃ­cio fÃ­sico",

     "message": "Defina dias fixos e trate o treino como compromisso.",

     "frequency\_per\_week": 3

   }

 ]

}





ğŸš€ **Como Executar o Projeto**



* Criar uma API no MockAPI com o schema de usuÃ¡rios



* Inserir usuÃ¡rios iniciais e obter seus IDs



* Criar um arquivo CSV contendo os IDs



* Executar o pipeline ETL em Python



* Verificar os usuÃ¡rios atualizados na API





ğŸ“ˆ **PossÃ­veis EvoluÃ§Ãµes**



* Adicionar timestamps aos insights gerados



* Implementar controle de erro e retentativas



* Salvar logs do pipeline



* Expandir para mÃºltiplos hÃ¡bitos por usuÃ¡rio



* Armazenar histÃ³rico de insights





ğŸ§¾ **ConclusÃ£o**



Este projeto demonstra a construÃ§Ã£o de um pipeline ETL funcional e realista, integrando dados estruturados, APIs REST e InteligÃªncia Artificial generativa.

A abordagem adotada reflete prÃ¡ticas utilizadas em ambientes profissionais de dados, com foco em clareza, modularizaÃ§Ã£o e aplicabilidade prÃ¡tica.



